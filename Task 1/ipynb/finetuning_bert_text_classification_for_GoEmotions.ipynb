{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1**\n",
        "---"
      ],
      "metadata": {
        "id": "_v6dGFL18z4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Library**"
      ],
      "metadata": {
        "id": "h4T-0RQf9PD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpDnR7XYiAgd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate accelerate scikit-learn matplotlib seaborn\n",
        "!pip install torch --upgrade\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SETUP & CONFIGURASI**"
      ],
      "metadata": {
        "id": "zHo4AGXn_VgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️ PERINGATAN: Anda tidak menggunakan GPU. Training akan sangat lambat!\")\n",
        "\n",
        "TOKEN = \"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\" # Ganti jika buat token baru\n",
        "login(token=TOKEN)\n",
        "\n",
        "# KONFIGURASI GO_EMOTIONS\n",
        "MODEL_CKPT = \"distilbert-base-uncased\"\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 3e-5\n",
        "MAX_LENGTH = 128\n",
        "SAMPLE_SIZE = 4000  # Jumlah sampel data\n",
        "SEED = 2025         # Seed agar hasil konsisten"
      ],
      "metadata": {
        "id": "jLpnQYjXlmkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOAD DATASET & LABEL MAPPING**"
      ],
      "metadata": {
        "id": "nvYLOJShA3BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "print(\"\\n--- Loading Dataset GoEmotions ---\")\n",
        "\n",
        "# Load Dataset\n",
        "dataset = load_dataset(\"go_emotions\", \"simplified\") # config 'simplified' agar lebih ringan\n",
        "\n",
        "# Ambil Daftar Nama Label\n",
        "labels_list = dataset[\"train\"].features[\"labels\"].feature.names\n",
        "NUM_LABELS = len(labels_list)\n",
        "\n",
        "# Mapping ID <-> Label\n",
        "id2label = {idx: label for idx, label in enumerate(labels_list)}\n",
        "label2id = {label: idx for idx, label in enumerate(labels_list)}\n",
        "\n",
        "print(f\"Total Labels: {NUM_LABELS}\")\n",
        "print(f\"Contoh Labels: {labels_list[:5]}...\") # Tampilkan 5 pertama aja\n",
        "\n",
        "# Sampling Data (Biar cepat)\n",
        "print(f\"\\nMelakukan sampling {SAMPLE_SIZE} data...\")\n",
        "\n",
        "def transform_labels(example):\n",
        "    # Ambil label pertama saja (Simplifikasi Multi-class)\n",
        "    label_id = example[\"labels\"][0] if len(example[\"labels\"]) > 0 else 27\n",
        "    return {\"labels\": label_id}\n",
        "\n",
        "formatted_dataset = dataset.map(transform_labels, remove_columns=[\"labels\"])\n",
        "train_dataset = formatted_dataset[\"train\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
        "eval_dataset = formatted_dataset[\"test\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE // 5))\n",
        "\n",
        "print(\"Sampling & Formatting Selesai!\")"
      ],
      "metadata": {
        "id": "aLltseIwntQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TOKENISASI**"
      ],
      "metadata": {
        "id": "gjbZfooDCGGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "print(\"\\n--- 3. Tokenizing ---\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "# Tokenisasi\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test = eval_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "cols_to_remove = [\"text\", \"id\"]\n",
        "\n",
        "tokenized_train = tokenized_train.remove_columns(cols_to_remove)\n",
        "tokenized_test = tokenized_test.remove_columns(cols_to_remove)\n",
        "\n",
        "# Set format ke PyTorch Tensor\n",
        "tokenized_train.set_format(\"torch\")\n",
        "tokenized_test.set_format(\"torch\")\n",
        "\n",
        "print(\"Tokenisasi Selesai. Kolom yang tersedia:\", tokenized_train.column_names)"
      ],
      "metadata": {
        "id": "tp8lSrECnvy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **METRICS**"
      ],
      "metadata": {
        "id": "s1dRHaf8Duti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
        "    f1_score = f1.compute(predictions=predictions, references=labels, average=\"weighted\") # Average='weighted' sangat penting karena data GoEmotions tidak seimbang\n",
        "\n",
        "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"]}"
      ],
      "metadata": {
        "id": "0IvJSR7QnxPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SETUP MODEL & TRAINER**"
      ],
      "metadata": {
        "id": "lq8EgS_fEG6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "print(\"\\n--- 5. Setup Model ---\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_CKPT,\n",
        "    num_labels=NUM_LABELS, # Otomatis 28\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "repo_name = \"finetuning-bert-text-classification-goemotions\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=repo_name,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=10, # Agar grafik muncul walau data sedikit\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "print(\"Setup Siap.\")"
      ],
      "metadata": {
        "id": "DrOF-BZqny4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EKSEKUSI TRAINING**"
      ],
      "metadata": {
        "id": "zZ7mZLAsF_Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 6. Mulai Training... ---\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n--- Uploading Model ---\")\n",
        "trainer.push_to_hub()\n",
        "print(\"Selesai! Cek akun Hugging Face Anda.\")"
      ],
      "metadata": {
        "id": "q70ZhXF4GFw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRAFIK**"
      ],
      "metadata": {
        "id": "cactSPKKGman"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = trainer.state.log_history\n",
        "steps = []\n",
        "losses = []\n",
        "\n",
        "for entry in history:\n",
        "    if \"loss\" in entry:\n",
        "        steps.append(entry[\"step\"])\n",
        "        losses.append(entry[\"loss\"])\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(steps, losses, label=\"Training Loss\", color=\"#2ca02c\",)\n",
        "plt.xlabel(\"Langkah (Steps)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Grafik Training GoEmotions\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_rk1elaoGrKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TES MANUAL**"
      ],
      "metadata": {
        "id": "wr0IcNTIGz4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_emotion(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
        "\n",
        "    # Ambil Top 5 Emosi\n",
        "    sorted_indices = probs.argsort()[::-1][:5]\n",
        "    sorted_probs = probs[sorted_indices]\n",
        "    sorted_labels = [id2label[idx] for idx in sorted_indices]\n",
        "\n",
        "    print(f\"\\n'{text}'\")\n",
        "    print(f\"Emosi Utama: {sorted_labels[0]} ({sorted_probs[0]:.2%})\")\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    ax = sns.barplot(x=sorted_probs, y=sorted_labels, palette=\"cool\") # Palette 'cool' cocok buat emosi\n",
        "    plt.xlabel(\"Confidence\")\n",
        "    plt.title(\"Top 5 Prediksi Emosi\")\n",
        "    plt.xlim(0, 1.1)\n",
        "\n",
        "    for i, v in enumerate(sorted_probs):\n",
        "        ax.text(v + 0.01, i, f\"{v:.2%}\", color='black', va='center')\n",
        "    plt.show()\n",
        "\n",
        "# CONTOH TES (Coba kalimat emosional)\n",
        "predict_emotion(\"I am so happy and grateful for this amazing gift!\")\n",
        "predict_emotion(\"This is absolutely terrible, I hate it so much.\")\n",
        "predict_emotion(\"I'm really worried about the exam tomorrow.\")"
      ],
      "metadata": {
        "id": "o42i1gVsG8kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VALIDATION METRICS**"
      ],
      "metadata": {
        "id": "xPP1rASMYIG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n--- 9. Menganalisis Performa Model ---\")\n",
        "\n",
        "# Ambil Riwayat Log dari Trainer\n",
        "history = trainer.state.log_history\n",
        "\n",
        "# Siapkan list untuk menampung data\n",
        "train_steps = []\n",
        "train_loss = []\n",
        "eval_steps = []\n",
        "eval_loss = []\n",
        "eval_acc = []\n",
        "eval_f1 = []\n",
        "\n",
        "# Ekstrak data dari history\n",
        "for entry in history:\n",
        "    if \"loss\" in entry: # data Training\n",
        "        train_steps.append(entry[\"step\"])\n",
        "        train_loss.append(entry[\"loss\"])\n",
        "    elif \"eval_loss\" in entry: # data Validation\n",
        "        eval_steps.append(entry[\"step\"])\n",
        "        eval_loss.append(entry[\"eval_loss\"])\n",
        "        eval_acc.append(entry[\"eval_accuracy\"])\n",
        "        if \"eval_f1\" in entry:\n",
        "            eval_f1.append(entry[\"eval_f1\"])\n",
        "\n",
        "# Training Loss vs Validation Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_steps, train_loss, label=\"Training Loss\", color=\"orange\", alpha=0.6)\n",
        "plt.plot(eval_steps, eval_loss, label=\"Validation Loss\", color=\"blue\", marker='o', linewidth=2)\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Validation Accuracy & F1 Score\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(eval_steps, eval_acc, label=\"Val Accuracy\", color=\"green\", marker='s', linewidth=2)\n",
        "if eval_f1:\n",
        "    plt.plot(eval_steps, eval_f1, label=\"Val F1 Score\", color=\"purple\", marker='^', linestyle='--')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Score (0.0 - 1.0)\")\n",
        "plt.title(\"Peningkatan Akurasi Model\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.ylim(0, 1.0) # Batas grafik 0 sampai 100%\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Hasil Akhir\n",
        "if eval_acc:\n",
        "    print(f\"\\nStatistik Akhir:\")\n",
        "    print(f\"Akurasi Terbaik: {max(eval_acc):.2%}\")\n",
        "    print(f\"Validation Loss Terendah: {min(eval_loss):.4f}\")\n",
        "    if eval_f1:\n",
        "        print(f\"F1 Score Terbaik: {max(eval_f1):.2%}\")\n",
        "else:\n",
        "    print(\"Data evaluasi tidak ditemukan\")"
      ],
      "metadata": {
        "id": "YwHB7dWGX_KK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}