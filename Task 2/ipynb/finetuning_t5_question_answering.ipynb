{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 2**"
      ],
      "metadata": {
        "id": "-WxHpLddNZRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INSTALASI**"
      ],
      "metadata": {
        "id": "L-kVoNP7NyBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install -U transformers accelerate datasets evaluate torch"
      ],
      "metadata": {
        "id": "0F4ozkma8m31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SETUP & LOAD DATASET**"
      ],
      "metadata": {
        "id": "tvowd7iUN-Pf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeMTzuUe8g2g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import shutil\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "\n",
        "# Masukkan Token\n",
        "TOKEN = \"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\"\n",
        "login(token=TOKEN)\n",
        "\n",
        "# Cek Hardware\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"✅ Hardware: {device}\")\n",
        "\n",
        "# Import Check\n",
        "print(\"✅ Import Library Berhasil (clear_device_cache error fixed).\")\n",
        "\n",
        "# Bersihkan Cache Dataset SQuAD\n",
        "cache_dir = os.path.expanduser(\"~/.cache/huggingface/datasets/squad\")\n",
        "if os.path.exists(cache_dir):\n",
        "    shutil.rmtree(cache_dir)\n",
        "\n",
        "# Load Dataset\n",
        "print(\"--- Memuat Dataset SQuAD ---\")\n",
        "raw_datasets = load_dataset(\"squad\", download_mode=\"force_redownload\")\n",
        "\n",
        "# Sampling Data\n",
        "train_data = raw_datasets[\"train\"].shuffle(seed=2024).select(range(4000))\n",
        "val_data = raw_datasets[\"validation\"].shuffle(seed=2024).select(range(800))\n",
        "\n",
        "print(f\"Data Siap: {len(train_data)} train, {len(val_data)} validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPROCESSING**"
      ],
      "metadata": {
        "id": "zwU2HnjLLcmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_CHECKPOINT = \"t5-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "MAX_INPUT = 512\n",
        "MAX_TARGET = 64\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Input: Gabungkan Question + Context\n",
        "    inputs = [f\"question: {q} context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
        "\n",
        "    # Target: Jawaban teks\n",
        "    targets = [ans[\"text\"][0] for ans in examples[\"answers\"]]\n",
        "\n",
        "    # 3. Tokenisasi Input\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # 4. Tokenisasi Output (Jawaban)\n",
        "    labels = tokenizer(targets, max_length=MAX_TARGET, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # TEKNIKAL: Mengganti token padding (0) menjadi -100 pada label, PyTorch akan mengabaikan nilai -100 saat menghitung Loss.\n",
        "    labels[\"input_ids\"] = [\n",
        "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "print(\"Memproses data menjadi format token...\")\n",
        "tokenized_train = train_data.map(preprocess_function, batched=True, remove_columns=raw_datasets[\"train\"].column_names)\n",
        "tokenized_val = val_data.map(preprocess_function, batched=True, remove_columns=raw_datasets[\"validation\"].column_names)\n",
        "print(\"Selesai.\")"
      ],
      "metadata": {
        "id": "l6VhTjvMLA4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SETUP MODEL - SEQ2SEQ**"
      ],
      "metadata": {
        "id": "nUsYK1nALjBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "\n",
        "# Definisi ulang variabel yang hilang\n",
        "MODEL_CHECKPOINT = \"t5-small\"\n",
        "batch_size = 8\n",
        "\n",
        "# Load Model Pre-trained T5\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n",
        "model.to(device)\n",
        "\n",
        "# Nama Repo\n",
        "repo_name = \"finetuning-t5-question-answering\"\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=repo_name,\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    push_to_hub=True,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(\"Trainer siap.\")"
      ],
      "metadata": {
        "id": "BXH7ScbpLCjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING**"
      ],
      "metadata": {
        "id": "sNVds9qjLlwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mulai Fine-Tuning T5...\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n--- Uploading ke Hugging Face ---\")\n",
        "trainer.push_to_hub()\n",
        "print(\"Selesai! Model sudah online.\")"
      ],
      "metadata": {
        "id": "yAthe6J4LERq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VISUALISASI**"
      ],
      "metadata": {
        "id": "6aq0IrzyLqLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = trainer.state.log_history\n",
        "steps = []\n",
        "losses = []\n",
        "\n",
        "# Ekstrak data loss\n",
        "for entry in history:\n",
        "    if \"loss\" in entry:\n",
        "        steps.append(entry[\"step\"])\n",
        "        losses.append(entry[\"loss\"])\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(steps, losses, label=\"Training Loss\", color=\"#008080\", marker='o')\n",
        "plt.xlabel(\"Langkah Training (Steps)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Kurva Pembelajaran Model T5 (SQuAD)\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s3iuuRv-LFrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INFERENCE**"
      ],
      "metadata": {
        "id": "8id5Shp5LuMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Pembantu untuk Melakukan Prediksi\n",
        "def ask_t5(context, question):\n",
        "    # Format Input sesuai format T5\n",
        "    input_text = f\"question: {question} context: {context}\"\n",
        "\n",
        "    # Tokenisasi\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate Jawaban\n",
        "    outputs = model.generate(**inputs, max_length=64)\n",
        "\n",
        "    # Decode\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"TANYA: {question}\")\n",
        "    print(f\"JAWAB: {answer}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# --- TES 1 ---\n",
        "context_1 = \"\"\"\n",
        "Borobudur is a 9th-century Mahayana Buddhist temple in Magelang Regency,\n",
        "not far from the town of Muntilan, in Central Java, Indonesia.\n",
        "It is the world's largest Buddhist temple. The temple consists of nine stacked platforms,\n",
        "six square and three circular, topped by a central dome.\n",
        "\"\"\"\n",
        "ask_t5(context_1, \"Where is Borobudur located?\")\n",
        "ask_t5(context_1, \"What consists of nine stacked platforms?\")\n",
        "\n",
        "# --- TES 2: ---\n",
        "context_2 = \"\"\"\n",
        "Python is a high-level, general-purpose programming language.\n",
        "Its design philosophy emphasizes code readability with the use of significant indentation.\n",
        "Python is dynamically typed and garbage-collected.\n",
        "\"\"\"\n",
        "ask_t5(context_2, \"What is Python?\")\n",
        "ask_t5(context_2, \"What does Python design emphasize?\")"
      ],
      "metadata": {
        "id": "cwchvmv4LHEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}